{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bcb5d57",
   "metadata": {},
   "source": [
    "<h2 align='center'>Solving a classification use-case in Pyspark </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf4d3b4",
   "metadata": {},
   "source": [
    "### Imports and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ec86a179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "99b43972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://KD:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PysparkML</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x18c1a462260>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark=SparkSession.builder.appName(\"PysparkML\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "d366bed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.ml                 \n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.sql.types import DoubleType, IntegerType\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2760c1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+---+---+----+----+----+----+---+-----+----+-----+----+----+\n",
      "|_c0|     Category|Age|Sex| ALB| ALP| ALT| AST|BIL|  CHE|CHOL| CREA| GGT|PROT|\n",
      "+---+-------------+---+---+----+----+----+----+---+-----+----+-----+----+----+\n",
      "|  1|0=Blood Donor| 32|  m|38.5|52.5| 7.7|22.1|7.5| 6.93|3.23|106.0|12.1|  69|\n",
      "|  2|0=Blood Donor| 32|  m|38.5|70.3|  18|24.7|3.9|11.17| 4.8| 74.0|15.6|76.5|\n",
      "|  3|0=Blood Donor| 32|  m|46.9|74.7|36.2|52.6|6.1| 8.84| 5.2| 86.0|33.2|79.3|\n",
      "+---+-------------+---+---+----+----+----+----+---+-----+----+-----+----+----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark=spark.read.option('header','true').csv(\"UCIData.txt\",inferSchema=True)\n",
    "df_pyspark.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c9fd4021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_c0', 'Category', 'Age', 'Sex', 'ALB', 'ALP', 'ALT', 'AST', 'BIL', 'CHE', 'CHOL', 'CREA', 'GGT', 'PROT']\n"
     ]
    }
   ],
   "source": [
    "print(df_pyspark.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3803d2c",
   "metadata": {},
   "source": [
    "### Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "25b0aea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rearraging columns\n",
    "df_pyspark=df_pyspark.select('Age', 'Sex', 'ALB', 'ALP', 'ALT', 'AST', 'BIL', 'CHE', 'CHOL', 'CREA', 'GGT', 'PROT', 'Category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e46ee2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+----+----+----+----+-----+----+-----+----+----+-------------+\n",
      "|Age|Sex| ALB| ALP| ALT| AST| BIL|  CHE|CHOL| CREA| GGT|PROT|     Category|\n",
      "+---+---+----+----+----+----+----+-----+----+-----+----+----+-------------+\n",
      "| 32|  m|38.5|52.5| 7.7|22.1| 7.5| 6.93|3.23|106.0|12.1|  69|0=Blood Donor|\n",
      "| 32|  m|38.5|70.3|  18|24.7| 3.9|11.17| 4.8| 74.0|15.6|76.5|0=Blood Donor|\n",
      "| 32|  m|46.9|74.7|36.2|52.6| 6.1| 8.84| 5.2| 86.0|33.2|79.3|0=Blood Donor|\n",
      "| 32|  m|43.2|  52|30.6|22.6|18.9| 7.33|4.74| 80.0|33.8|75.7|0=Blood Donor|\n",
      "+---+---+----+----+----+----+----+-----+----+-----+----+----+-------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4df640b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Converting sex=(m,f) into vectors=(1,0)\n",
    "gender_encoder=StringIndexer(inputCol='Sex',outputCol='sex').fit(df_pyspark)\n",
    "df_pyspark=gender_encoder.transform(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f2d263d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LabelEncoding of Category\n",
    "target_encoder=StringIndexer(inputCol='Category',outputCol='category').fit(df_pyspark)\n",
    "df_pyspark=target_encoder.transform(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "14693501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+----+----+----+---+-----+----+-----+----+----+--------+\n",
      "|Age|sex| ALB| ALP| ALT| AST|BIL|  CHE|CHOL| CREA| GGT|PROT|category|\n",
      "+---+---+----+----+----+----+---+-----+----+-----+----+----+--------+\n",
      "| 32|0.0|38.5|52.5| 7.7|22.1|7.5| 6.93|3.23|106.0|12.1|  69|     0.0|\n",
      "| 32|0.0|38.5|70.3|  18|24.7|3.9|11.17| 4.8| 74.0|15.6|76.5|     0.0|\n",
      "| 32|0.0|46.9|74.7|36.2|52.6|6.1| 8.84| 5.2| 86.0|33.2|79.3|     0.0|\n",
      "+---+---+----+----+----+----+---+-----+----+-----+----+----+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6d86d27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- sex: double (nullable = false)\n",
      " |-- ALB: string (nullable = true)\n",
      " |-- ALP: string (nullable = true)\n",
      " |-- ALT: string (nullable = true)\n",
      " |-- AST: double (nullable = true)\n",
      " |-- BIL: double (nullable = true)\n",
      " |-- CHE: double (nullable = true)\n",
      " |-- CHOL: string (nullable = true)\n",
      " |-- CREA: double (nullable = true)\n",
      " |-- GGT: double (nullable = true)\n",
      " |-- PROT: string (nullable = true)\n",
      " |-- category: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Checking the null value count in each column\n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ba958106",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Converting the string type columns into double \n",
    "for i in range(len(df_pyspark.columns)):\n",
    "    column_name=df_pyspark.columns[i]\n",
    "    if df_pyspark.select(column_name).dtypes[0][1]=='string':\n",
    "        df_pyspark=df_pyspark.withColumn(column_name,df_pyspark[column_name].cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e23a6b4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values in 'Age' column = 0\n",
      "Null values in 'sex' column = 0\n",
      "Null values in 'ALB' column = 1\n",
      "Null values in 'ALP' column = 18\n",
      "Null values in 'ALT' column = 1\n",
      "Null values in 'AST' column = 0\n",
      "Null values in 'BIL' column = 0\n",
      "Null values in 'CHE' column = 0\n",
      "Null values in 'CHOL' column = 10\n",
      "Null values in 'CREA' column = 0\n",
      "Null values in 'GGT' column = 0\n",
      "Null values in 'PROT' column = 1\n",
      "Null values in 'category' column = 0\n"
     ]
    }
   ],
   "source": [
    "# Pyspark 'DataFrame' object has no attribute 'isNull'\n",
    "for i in df_pyspark.columns:\n",
    "    print(\"Null values in '{}' column = {}\".format(i,df_pyspark.filter(df_pyspark[i].isNull()).count()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "eb429fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark=df_pyspark.fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f12fe108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values in 'Age' column = 0\n",
      "Null values in 'sex' column = 0\n",
      "Null values in 'ALB' column = 0\n",
      "Null values in 'ALP' column = 0\n",
      "Null values in 'ALT' column = 0\n",
      "Null values in 'AST' column = 0\n",
      "Null values in 'BIL' column = 0\n",
      "Null values in 'CHE' column = 0\n",
      "Null values in 'CHOL' column = 0\n",
      "Null values in 'CREA' column = 0\n",
      "Null values in 'GGT' column = 0\n",
      "Null values in 'PROT' column = 0\n",
      "Null values in 'category' column = 0\n"
     ]
    }
   ],
   "source": [
    "# Pyspark 'DataFrame' object has no attribute 'isNull'\n",
    "for i in df_pyspark.columns:\n",
    "    print(\"Null values in '{}' column = {}\".format(i,df_pyspark.filter(df_pyspark[i].isNull()).count()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4ffc4c",
   "metadata": {},
   "source": [
    "### Split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f2a1631c",
   "metadata": {},
   "outputs": [],
   "source": [
    "required_features = ['Age', 'sex', 'ALB', 'ALP', 'ALT', 'AST', 'BIL', 'CHE', 'CHOL', 'CREA', 'GGT', 'PROT']\n",
    "target_feature = 'category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a546ced2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Converting the features into vectors\n",
    "vector_assembler = VectorAssembler(inputCols=required_features, outputCol='feature_vector')\n",
    "x_and_y =vector_assembler.transform(df_pyspark).select('feature_vector','category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "97da77c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the Training Dataset :  518\n",
      "Shape of the Testing Dataset :  97\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = x_and_y.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print(\"Shape of the Training Dataset : \", train_df.count())      \n",
    "print(\"Shape of the Testing Dataset : \", test_df.count())    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc42b5a",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "2d5c143d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol= 'feature_vector', labelCol = 'category')\n",
    "trained_lr_model = lr.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "df734bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+--------------------+--------------------+----------+\n",
      "|      feature_vector|category|       rawPrediction|         probability|prediction|\n",
      "+--------------------+--------+--------------------+--------------------+----------+\n",
      "|[25.0,0.0,42.0,38...|     2.0|[-41.628181598119...|[5.65413878652831...|       1.0|\n",
      "|[30.0,0.0,45.0,0....|     2.0|[0.71096218451604...|[0.00228691751385...|       2.0|\n",
      "|[32.0,0.0,38.5,70...|     0.0|[16.2569657704463...|[0.99999994032107...|       0.0|\n",
      "|[32.0,0.0,42.4,86...|     0.0|[15.4168032946208...|[0.99999878039966...|       0.0|\n",
      "|[32.0,0.0,50.9,65...|     0.0|[17.8169752935213...|[0.99999862762836...|       0.0|\n",
      "|[32.0,1.0,47.4,52...|     0.0|[19.1857356209346...|[0.99999966436415...|       0.0|\n",
      "|[33.0,0.0,41.8,65...|     0.0|[11.4505023012611...|[0.99996262490845...|       0.0|\n",
      "|[33.0,1.0,35.4,53...|     0.0|[13.7571421135942...|[0.99997446573648...|       0.0|\n",
      "|[33.0,1.0,43.0,29...|     2.0|[11.2752904908514...|[0.90266733506628...|       0.0|\n",
      "|[33.0,1.0,44.3,74...|     0.0|[10.4243678529581...|[0.99643805054492...|       0.0|\n",
      "+--------------------+--------+--------------------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = trained_lr_model.transform(test_df)\n",
    "y_pred.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0af273",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "893b9a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model :  0.9072164948453608\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='category', metricName='accuracy')\n",
    "accuracy = evaluator.evaluate(y_pred)\n",
    "print(\"Accuracy of the model : \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b79aeb79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score of the model :  0.9135488010046513\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='category', metricName='f1')\n",
    "f1_score = evaluator.evaluate(y_pred)\n",
    "print(\"F1-Score of the model : \",f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf56367",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "979b270c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_lr_model.save(spark, \"lr_classification_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dfddc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
